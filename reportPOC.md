# Rapport ‚Äî Planification de trajectoire d‚Äôun robot mobile par SLPSO (Self-Adaptive Learning Particle Swarm Optimization)

## R√©sum√©
Ce rapport pr√©sente une preuve de concept (PoC) de planification de trajectoire pour robot mobile en environnement 2D avec obstacles statiques. Le probl√®me est formul√© comme une optimisation multi-objectif minimisant simultan√©ment : (i) la longueur du chemin, (ii) le risque de collision, et (iii) la douceur (smoothness) de la trajectoire. La m√©thode √©tudi√©e est SLPSO, une variante de PSO int√©grant quatre op√©rateurs d‚Äôapprentissage et un m√©canisme auto-adaptatif des probabilit√©s de s√©lection.

## 1) Introduction au probl√®me et √† sa mod√©lisation

### 1.1 Probl√®me de planification de trajectoire (Path Planning)

On cherche une trajectoire **sans collision** entre un point de d√©part **S** et une cible **T**, dans un environnement 2D contenant des obstacles statiques (formes diverses). Le probl√®me est formul√© comme une **optimisation sous contraintes** : minimiser une fonction objectif tout en garantissant l‚Äôabsence de collision. 

### 1.2 Mod√©lisation du chemin par waypoints dans un rep√®re local

L‚Äôarticle propose de repr√©senter un chemin par **D waypoints internes** (sans compter S et T).  
Les auteurs fixent les coordonn√©es **x‚Äô** des waypoints en divisant uniform√©ment la distance \|ST\| en **D+1 segments** dans un rep√®re local \(S - X'Y'\). L‚Äôoptimisation ne cherche alors que les d√©viations **y‚Äô** sur des droites verticales \(L_1 \dots L_D\). 

Transformation local ‚Üí global : on applique une rotation (angle \(\theta\) entre l‚Äôaxe global et le segment ST) puis une translation par S. 

**Pourquoi cette mod√©lisation ?**
- elle r√©duit la dimension utile : chaque particule de l‚Äôessaim n‚Äôencode que les **D valeurs y‚Äô** ;
- elle garantit que les points progressent dans la direction globale S‚ÜíT (via x‚Äô uniformes). 

---

## 2) Crit√®res d‚Äô√©valuation d‚Äôune solution

Les auteurs combinent trois crit√®res (multi-objectif) via une somme pond√©r√©e (m√©thode additive). 

### 2.1 Longueur du chemin \(L(P)\)
Somme des distances euclidiennes entre points successifs (S, waypoints, T). 

### 2.2 Risque de collision \(R(X_{rob}, X_{obs})\)
Risque bas√© sur un **mod√®le Gaussien-like 2D** : le risque est non nul dans une zone d‚Äôinfluence autour des obstacles et nul au-del√†, avec des param√®tres de forme (variance/port√©e) choisis par l‚Äôauteur. 

> Dans une impl√©mentation ‚Äúpreuve de concept‚Äù, on peut remplacer ce mod√®le continu par une version **√©chantillonn√©e le long des segments** (d√©tection collision + p√©nalit√© de proximit√©), tout en conservant l‚Äôesprit de l‚Äô√©quation (5) (p√©naliser la proximit√©).

### 2.3 Douceur \(S(P)\) (smoothness)
Somme des angles de d√©flexion (entre trois waypoints cons√©cutifs). Plus le chemin ‚Äúzigzague‚Äù, plus \(S(P)\) augmente. 

### 2.4 Fonction objectif globale
\[
J = w_1 L + w_2 R + w_3 S
\]
Les poids d√©pendent du contexte ; dans l‚Äôarticle : **\(w_1=0.6, w_2=0.3, w_3=0.1\)**. 

---

## 3) Dataset(s) de r√©f√©rence et m√©triques

### 3.1 R√©f√©rences ‚Äúdatasets‚Äù dans l‚Äôarticle

1) **Benchmark d‚Äôoptimisation** : testbed CEC-2013 (28 fonctions) pour montrer que SLPSO est un bon optimiseur g√©n√©rique.   
2) **Environnement simul√©** (ROS + Gazebo/Player-Stage) : workspace **12m √ó 12m**, obstacles vari√©s, gap minimal ‚âà 0.5m. D√©part (1,1) ‚Üí cible (11,11).   
3) **Environnement r√©el** (TurtleBot2) : workspace **12m √ó 12m**, gap minimal ‚âà 0.6m, D=20.   

### 3.2 M√©triques suivies
- \(L\) (m), \(R\) (degr√© de risque), \(S\) (rad) et co√ªt global \(J\).   
- **Temps de calcul** / running time.   

### 3.3 Param√®tres exp√©rimentaux (article)
- Population **N=30** (PSO et SLPSO) ; **Itermax = 150** ; fr√©quence d‚Äôupdate des ratios **Uf = 3** ; \(\eta_3=1.496\).   
- D varie de **5 √† 30** pour √©tudier l‚Äôimpact du nombre de waypoints.   
- Crit√®re d‚Äôarr√™t : Itermax ou am√©lioration minimale (‚âà 1% sur 10 it√©rations).   

---

## 4) R√©solution du probl√®me : du PSO standard √† SLPSO

### 4.1 PSO standard (rappel)

Chaque particule i poss√®de :
- une position \(X_i\) (ici : les D valeurs y‚Äô),
- une vitesse \(V_i\),
- un **Pbest** (meilleure position personnelle) et un **Gbest** (meilleure globale).   

La mise √† jour classique combine inertie + apprentissage depuis Pbest et Gbest. 

### 4.2 SLPSO : id√©e cl√©

SLPSO emploie **4 op√©rateurs d‚Äôapprentissage** (a,b,c,d) :  
- **a (exploitation)** : apprendre depuis Pbest,  
- **b (convergence)** : apprendre depuis le meilleur voisin ‚Äúle plus proche‚Äù,  
- **c (sortie d‚Äôoptimum local)** : perturbation,  
- **d (exploration)** : apprendre depuis Gbest.   

Les probabilit√©s de s√©lection sont **auto-adapt√©es** selon succ√®s + progr√®s (fen√™tre de taille Uf). 

---

## 5) Mod√©lisation du ‚Äúproblem solving‚Äù (pseudocode, diagrammes) + complexit√©

### 5.1 Pseudocode (niveau notebook)

```text
Entr√©es : environnement, S, T, D, N, Itermax, Uf, param√®tres (w1,w2,w3, Œ∑3, Vmax, bornes y')

1. Construire le rep√®re local S-X'Y' ; fixer x'(d)=|ST|/(D+1)*d
2. Initialiser N particules (y' et V), Pbest=position initiale
3. √âvaluer chaque particule ‚Üí initialiser Gbest
4. Pour k = 1..Itermax :
      Pour chaque particule i :
          si k mod Uf == 0 : mettre √† jour ratios (auto-adaptatif)
          choisir un op√©rateur (a,b,c,d) selon ratios
          mettre √† jour vitesse/position selon op√©rateur
          g√©rer violations de bornes (Vmax + r√©flexion des positions)
          √©valuer J ; mettre √† jour Pbest/Gbest
5. Sortie : meilleur chemin = local_to_global(Gbest)
Ce flux correspond √† l‚ÄôAlgorithm 1.
'''

## 5.2 Complexit√©

Temps : O(D¬∑T¬∑N).

M√©moire : O(N¬∑D).

## 6) Narratives et cas d‚Äôusage (reproductibles)

### 6.1 Cas d‚Äôusage minimal (POC)

Workspace 2D, obstacles statiques.

D√©part S et cible T.

Param√®tres : 
ùëÅ
=
30
N=30, Itermax=150, D choisi (ex : 5).

### 6.2 Reproductibilit√© (seed)

```python
import numpy as np, random
SEED = 42
np.random.seed(SEED)
random.seed(SEED)
